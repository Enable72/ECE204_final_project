{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c9864b7-fd98-4d3a-845a-3b6f0aa863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import CoxPHFitter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecb789d5-0538-4027-8b7a-7231ab8b22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('Full Data.txt', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0508d1cc-988c-449f-bec5-852a581f28f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ajcc_pathologic_tumor_stage</th>\n",
       "      <th>tumor_status</th>\n",
       "      <th>DSS</th>\n",
       "      <th>DSS.time</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TTN</th>\n",
       "      <th>FAT1</th>\n",
       "      <th>MUC16</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>...</th>\n",
       "      <th>NIPBL</th>\n",
       "      <th>CEACAM5</th>\n",
       "      <th>CEACAM6</th>\n",
       "      <th>CLCA4</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>Missense_Mutation</th>\n",
       "      <th>Nonsense_Mutation</th>\n",
       "      <th>Nonstop_Mutation</th>\n",
       "      <th>Splice_Site</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-4P-AA8J</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279452</td>\n",
       "      <td>822.678</td>\n",
       "      <td>1157.3300</td>\n",
       "      <td>1620.71</td>\n",
       "      <td>1004.4700</td>\n",
       "      <td>1.2325</td>\n",
       "      <td>...</td>\n",
       "      <td>1595.440</td>\n",
       "      <td>56.0776</td>\n",
       "      <td>423.3550</td>\n",
       "      <td>502.2340</td>\n",
       "      <td>722.847</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BA-4074</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.265753</td>\n",
       "      <td>1805.510</td>\n",
       "      <td>103.6870</td>\n",
       "      <td>6415.45</td>\n",
       "      <td>17.3422</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>...</td>\n",
       "      <td>1605.890</td>\n",
       "      <td>153.3820</td>\n",
       "      <td>275.9330</td>\n",
       "      <td>12.7176</td>\n",
       "      <td>1267.900</td>\n",
       "      <td>106</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BA-4075</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>383.760</td>\n",
       "      <td>295.9180</td>\n",
       "      <td>4162.40</td>\n",
       "      <td>1.0720</td>\n",
       "      <td>36.9824</td>\n",
       "      <td>...</td>\n",
       "      <td>907.410</td>\n",
       "      <td>18.2232</td>\n",
       "      <td>45.5581</td>\n",
       "      <td>10.1836</td>\n",
       "      <td>4833.430</td>\n",
       "      <td>113</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BA-4077</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.106849</td>\n",
       "      <td>1929.260</td>\n",
       "      <td>207.3870</td>\n",
       "      <td>7246.87</td>\n",
       "      <td>432.6270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1174.690</td>\n",
       "      <td>2392.6900</td>\n",
       "      <td>2437.9200</td>\n",
       "      <td>720.8850</td>\n",
       "      <td>2371.940</td>\n",
       "      <td>234</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BA-5149</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.208219</td>\n",
       "      <td>165.298</td>\n",
       "      <td>347.9540</td>\n",
       "      <td>8848.73</td>\n",
       "      <td>110.5410</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>...</td>\n",
       "      <td>1798.770</td>\n",
       "      <td>37.3032</td>\n",
       "      <td>447.6390</td>\n",
       "      <td>5.4757</td>\n",
       "      <td>6934.280</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-UF-A7JO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.728767</td>\n",
       "      <td>1604.880</td>\n",
       "      <td>176.1930</td>\n",
       "      <td>1881.36</td>\n",
       "      <td>347.7040</td>\n",
       "      <td>2.8008</td>\n",
       "      <td>...</td>\n",
       "      <td>854.256</td>\n",
       "      <td>1498.8500</td>\n",
       "      <td>2014.6000</td>\n",
       "      <td>82.8248</td>\n",
       "      <td>530.911</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-UF-A7JS</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.863014</td>\n",
       "      <td>2457.400</td>\n",
       "      <td>1379.4300</td>\n",
       "      <td>1339.31</td>\n",
       "      <td>243.6470</td>\n",
       "      <td>19.4320</td>\n",
       "      <td>...</td>\n",
       "      <td>982.063</td>\n",
       "      <td>358.7440</td>\n",
       "      <td>294.4690</td>\n",
       "      <td>32.8849</td>\n",
       "      <td>246.637</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-UF-A7JT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.720548</td>\n",
       "      <td>1684.850</td>\n",
       "      <td>149.5190</td>\n",
       "      <td>3430.74</td>\n",
       "      <td>213.8530</td>\n",
       "      <td>14.2857</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.520</td>\n",
       "      <td>49.7835</td>\n",
       "      <td>209.5240</td>\n",
       "      <td>200.4330</td>\n",
       "      <td>790.905</td>\n",
       "      <td>152</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-UF-A7JV</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>1638.760</td>\n",
       "      <td>70.3028</td>\n",
       "      <td>8594.83</td>\n",
       "      <td>138.0370</td>\n",
       "      <td>63.8277</td>\n",
       "      <td>...</td>\n",
       "      <td>1167.360</td>\n",
       "      <td>680.1880</td>\n",
       "      <td>367.9710</td>\n",
       "      <td>464.8660</td>\n",
       "      <td>2120.820</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-WA-A7H4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213699</td>\n",
       "      <td>683.494</td>\n",
       "      <td>22512.9000</td>\n",
       "      <td>4439.10</td>\n",
       "      <td>188.3010</td>\n",
       "      <td>22.4359</td>\n",
       "      <td>...</td>\n",
       "      <td>2209.940</td>\n",
       "      <td>122.5960</td>\n",
       "      <td>4175.4800</td>\n",
       "      <td>73.7179</td>\n",
       "      <td>2365.340</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              gender  ajcc_pathologic_tumor_stage  tumor_status  DSS  \\\n",
       "patient_id                                                             \n",
       "TCGA-4P-AA8J       1                            0             0  0.0   \n",
       "TCGA-BA-4074       1                            0             1  1.0   \n",
       "TCGA-BA-4075       1                            1             1  1.0   \n",
       "TCGA-BA-4077       0                            0             1  1.0   \n",
       "TCGA-BA-5149       1                            0             1  1.0   \n",
       "...              ...                          ...           ...  ...   \n",
       "TCGA-UF-A7JO       0                            0             1  1.0   \n",
       "TCGA-UF-A7JS       1                            0             1  1.0   \n",
       "TCGA-UF-A7JT       0                            0             1  1.0   \n",
       "TCGA-UF-A7JV       0                            0             1  1.0   \n",
       "TCGA-WA-A7H4       1                            1             0  0.0   \n",
       "\n",
       "              DSS.time      TP53         TTN     FAT1      MUC16    CSMD3  \\\n",
       "patient_id                                                                  \n",
       "TCGA-4P-AA8J  0.279452   822.678   1157.3300  1620.71  1004.4700   1.2325   \n",
       "TCGA-BA-4074  1.265753  1805.510    103.6870  6415.45    17.3422   0.3854   \n",
       "TCGA-BA-4075  0.775342   383.760    295.9180  4162.40     1.0720  36.9824   \n",
       "TCGA-BA-4077  3.106849  1929.260    207.3870  7246.87   432.6270   0.0000   \n",
       "TCGA-BA-5149  2.208219   165.298    347.9540  8848.73   110.5410   0.3422   \n",
       "...                ...       ...         ...      ...        ...      ...   \n",
       "TCGA-UF-A7JO  1.728767  1604.880    176.1930  1881.36   347.7040   2.8008   \n",
       "TCGA-UF-A7JS  1.863014  2457.400   1379.4300  1339.31   243.6470  19.4320   \n",
       "TCGA-UF-A7JT  2.720548  1684.850    149.5190  3430.74   213.8530  14.2857   \n",
       "TCGA-UF-A7JV  0.246575  1638.760     70.3028  8594.83   138.0370  63.8277   \n",
       "TCGA-WA-A7H4  1.213699   683.494  22512.9000  4439.10   188.3010  22.4359   \n",
       "\n",
       "              ...     NIPBL    CEACAM5    CEACAM6     CLCA4      EGFR  \\\n",
       "patient_id    ...                                                       \n",
       "TCGA-4P-AA8J  ...  1595.440    56.0776   423.3550  502.2340   722.847   \n",
       "TCGA-BA-4074  ...  1605.890   153.3820   275.9330   12.7176  1267.900   \n",
       "TCGA-BA-4075  ...   907.410    18.2232    45.5581   10.1836  4833.430   \n",
       "TCGA-BA-4077  ...  1174.690  2392.6900  2437.9200  720.8850  2371.940   \n",
       "TCGA-BA-5149  ...  1798.770    37.3032   447.6390    5.4757  6934.280   \n",
       "...           ...       ...        ...        ...       ...       ...   \n",
       "TCGA-UF-A7JO  ...   854.256  1498.8500  2014.6000   82.8248   530.911   \n",
       "TCGA-UF-A7JS  ...   982.063   358.7440   294.4690   32.8849   246.637   \n",
       "TCGA-UF-A7JT  ...  1009.520    49.7835   209.5240  200.4330   790.905   \n",
       "TCGA-UF-A7JV  ...  1167.360   680.1880   367.9710  464.8660  2120.820   \n",
       "TCGA-WA-A7H4  ...  2209.940   122.5960  4175.4800   73.7179  2365.340   \n",
       "\n",
       "              Missense_Mutation  Nonsense_Mutation  Nonstop_Mutation  \\\n",
       "patient_id                                                             \n",
       "TCGA-4P-AA8J                 92                  8                 0   \n",
       "TCGA-BA-4074                106                  8                 0   \n",
       "TCGA-BA-4075                113                 10                 0   \n",
       "TCGA-BA-4077                234                 20                 0   \n",
       "TCGA-BA-5149                 96                  6                 0   \n",
       "...                         ...                ...               ...   \n",
       "TCGA-UF-A7JO                135                  9                 0   \n",
       "TCGA-UF-A7JS                 50                  1                 0   \n",
       "TCGA-UF-A7JT                152                 10                 0   \n",
       "TCGA-UF-A7JV                 52                  8                 0   \n",
       "TCGA-WA-A7H4                 60                  0                 0   \n",
       "\n",
       "              Splice_Site  age  \n",
       "patient_id                      \n",
       "TCGA-4P-AA8J            2    1  \n",
       "TCGA-BA-4074            1    1  \n",
       "TCGA-BA-4075            4    0  \n",
       "TCGA-BA-4077            6    0  \n",
       "TCGA-BA-5149            0    0  \n",
       "...                   ...  ...  \n",
       "TCGA-UF-A7JO            4    1  \n",
       "TCGA-UF-A7JS            1    1  \n",
       "TCGA-UF-A7JT            3    1  \n",
       "TCGA-UF-A7JV            2    1  \n",
       "TCGA-WA-A7H4            0    1  \n",
       "\n",
       "[450 rows x 106 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64beada1-7def-407c-8505-b1d89012f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = range(1,11)\n",
    "n_components = 3  # Specify the number of components\n",
    "nmf = NMF(n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "419464d1-2825-4bb6-b18d-276222264886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation_svm(df):\n",
    "    # get features you select\n",
    "    X = df.drop(columns = ['DSS.time', 'DSS'])\n",
    "    y = df['DSS']\n",
    "\n",
    "    # Split the dataset into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # SVM\n",
    "   \n",
    "    # Define the model\n",
    "    svm_clf = svm.SVC()\n",
    "\n",
    "    # Train the model\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "   \n",
    "    # Predict on the test set\n",
    "    svm_predictions = svm_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    return accuracy_score(y_test, svm_predictions)\n",
    "    #print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bfc0d88-7ae2-4fe4-844b-525e32b2343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time limit 1 and nmf features\n",
      "SVM Accuracy 0.7327272727272728\n",
      "For time limit 2 and nmf features\n",
      "SVM Accuracy 0.6998076923076922\n",
      "For time limit 3 and nmf features\n",
      "SVM Accuracy 0.669393939393939\n",
      "For time limit 4 and nmf features\n",
      "SVM Accuracy 0.7045205479452059\n",
      "For time limit 5 and nmf features\n",
      "SVM Accuracy 0.721125\n",
      "For time limit 6 and nmf features\n",
      "SVM Accuracy 0.7057831325301204\n",
      "For time limit 7 and nmf features\n",
      "SVM Accuracy 0.708235294117647\n",
      "For time limit 8 and nmf features\n",
      "SVM Accuracy 0.7124137931034484\n",
      "For time limit 9 and nmf features\n",
      "SVM Accuracy 0.7118181818181819\n",
      "For time limit 10 and nmf features\n",
      "SVM Accuracy 0.706590909090909\n"
     ]
    }
   ],
   "source": [
    "for i in time_limit:\n",
    "    data = full_data[full_data['DSS.time'] <= i]\n",
    "    X_reduced = nmf.fit_transform(data)\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns= ['component_1', 'component_2', 'component_3'])\n",
    "    df_reduced['DSS'] = full_data['DSS'].reset_index()['DSS']\n",
    "    df_reduced['DSS.time'] = full_data['DSS.time'].reset_index()['DSS.time']\n",
    "    lis = []\n",
    "    for k in range(100):\n",
    "        accuracy = classifcation_svm(df_reduced)\n",
    "        lis.append(accuracy)\n",
    "    mean_acc = sum(lis)/len(lis)\n",
    "    print('For time limit ' + str(i) + ' and nmf features')\n",
    "    print('SVM Accuracy ' + str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "937ff364-cdd5-4d2d-9590-ca136a85caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation_randomforest(df):\n",
    "    # get features you select\n",
    "    X = df.drop(columns = ['DSS.time', 'DSS'])\n",
    "    y = df['DSS']\n",
    "\n",
    "    # Split the dataset into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # add classification\n",
    "    # choose any classfication to do prediction\n",
    "    # Define the model\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    # Train the model\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    # Predict on the test set\n",
    "    rf_predictions = rf_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    return accuracy_score(y_test, rf_predictions)\n",
    "    #print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10dc715d-9100-4f9c-b100-3eeb8a0d6601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time limit 1 and nmf features\n",
      "Random Forest Accuracy 0.6813636363636363\n",
      "For time limit 2 and nmf features\n",
      "Random Forest Accuracy 0.6453846153846153\n",
      "For time limit 3 and nmf features\n",
      "Random Forest Accuracy 0.6048484848484853\n",
      "For time limit 4 and nmf features\n",
      "Random Forest Accuracy 0.6698630136986304\n",
      "For time limit 5 and nmf features\n",
      "Random Forest Accuracy 0.6445000000000001\n",
      "For time limit 6 and nmf features\n",
      "Random Forest Accuracy 0.6609638554216869\n",
      "For time limit 7 and nmf features\n",
      "Random Forest Accuracy 0.6238823529411767\n",
      "For time limit 8 and nmf features\n",
      "Random Forest Accuracy 0.6509195402298852\n",
      "For time limit 9 and nmf features\n",
      "Random Forest Accuracy 0.6334090909090907\n",
      "For time limit 10 and nmf features\n",
      "Random Forest Accuracy 0.660113636363636\n"
     ]
    }
   ],
   "source": [
    "for i in time_limit:\n",
    "    data = full_data[full_data['DSS.time'] <= i]\n",
    "    X_reduced = nmf.fit_transform(data)\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns= ['component_1', 'component_2', 'component_3'])\n",
    "    df_reduced['DSS'] = full_data['DSS'].reset_index()['DSS']\n",
    "    df_reduced['DSS.time'] = full_data['DSS.time'].reset_index()['DSS.time']\n",
    "    lis = []\n",
    "    for k in range(100):\n",
    "        accuracy = classifcation_randomforest(df_reduced)\n",
    "        lis.append(accuracy)\n",
    "    mean_acc = sum(lis)/len(lis)\n",
    "    print('For time limit ' + str(i) + ' and nmf features')\n",
    "    print('Random Forest Accuracy ' + str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6730243d-2c58-4d6d-bde8-6b033c8c42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation_logistic(df):\n",
    "    # get features you select\n",
    "    X = df.drop(columns = ['DSS.time', 'DSS'])\n",
    "    y = df['DSS']\n",
    "\n",
    "    # Split the dataset into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # add classification\n",
    "    # choose any classfication to do prediction\n",
    "    # Define the model\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    # Train the model\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    log_reg_predictions = log_reg.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    return accuracy_score(y_test, log_reg_predictions)\n",
    "    #print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, log_reg_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f1b178f-3e90-4941-b15b-54173994e83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time limit 1 and nmf features\n",
      "Logistic Accuracy 0.7177272727272728\n",
      "For time limit 2 and nmf features\n",
      "Logistic Accuracy 0.6998076923076922\n",
      "For time limit 3 and nmf features\n",
      "Logistic Accuracy 0.6703030303030303\n",
      "For time limit 4 and nmf features\n",
      "Logistic Accuracy 0.7028767123287674\n",
      "For time limit 5 and nmf features\n",
      "Logistic Accuracy 0.7039999999999996\n",
      "For time limit 6 and nmf features\n",
      "Logistic Accuracy 0.7084337349397586\n",
      "For time limit 7 and nmf features\n",
      "Logistic Accuracy 0.707882352941176\n",
      "For time limit 8 and nmf features\n",
      "Logistic Accuracy 0.7018390804597704\n",
      "For time limit 9 and nmf features\n",
      "Logistic Accuracy 0.7153409090909092\n",
      "For time limit 10 and nmf features\n",
      "Logistic Accuracy 0.7093181818181814\n"
     ]
    }
   ],
   "source": [
    "for i in time_limit:\n",
    "    data = full_data[full_data['DSS.time'] <= i]\n",
    "    X_reduced = nmf.fit_transform(data)\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns= ['component_1', 'component_2', 'component_3'])\n",
    "    df_reduced['DSS'] = full_data['DSS'].reset_index()['DSS']\n",
    "    df_reduced['DSS.time'] = full_data['DSS.time'].reset_index()['DSS.time']\n",
    "    lis = []\n",
    "    for k in range(100):\n",
    "        accuracy = classifcation_logistic(df_reduced)\n",
    "        lis.append(accuracy)\n",
    "    mean_acc = sum(lis)/len(lis)\n",
    "    print('For time limit ' + str(i) + ' and nmf features')\n",
    "    print('Logistic Accuracy ' + str(mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd64934-0209-422a-af3e-8827c882c18f",
   "metadata": {},
   "source": [
    "# Log-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72f6f2-b70a-4a05-8bbf-5f0c9ddf5716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3953930-f27f-46cf-94f7-fbd24a5530b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_gene(df, x):\n",
    "    q1 = df[x].quantile(0.1)\n",
    "    q3 = df[x].quantile(0.9)\n",
    "    df[x + 'binary'] = df[x].apply(lambda x: 0 if x <= q1 else 1 if x >= q3 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e603d606-496a-4ff1-95c0-90ba990faf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logrank(df, lis,time):\n",
    "    dic ={}\n",
    "    data = df[df['DSS.time'] <= time]\n",
    "    for i in lis:\n",
    "        quantile_gene(data, i)\n",
    "        low_expression = data[data[i + 'binary'] == 0]\n",
    "        high_expression =  data[data[i +'binary'] == 1]\n",
    "        # logrank\n",
    "        results = logrank_test(high_expression['DSS.time'], low_expression['DSS.time'],\n",
    "                       high_expression['DSS'], low_expression['DSS'])\n",
    "        z_value = results.test_statistic\n",
    "        if z_value > 1.96 or z_value < -1.96:\n",
    "            dic[i] = z_value\n",
    "    # return a dictionary of name and z value\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7119704f-dcc8-4a9b-a87f-39dc609a4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = list(full_data.drop(columns = ['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status', 'DSS' ,\n",
    "                                      'DSS.time', 'Missense_Mutation', 'Nonsense_Mutation', \n",
    "                                      'Nonstop_Mutation', 'Splice_Site', 'age']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e37c3a-be48-41a2-ba70-7dbca9c9c7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP53': 2.120617453561617,\n",
       " 'TTN': 2.143271855534282,\n",
       " 'CDKN2A': 3.1481755529943243,\n",
       " 'PIK3CA': 4.680473121342188,\n",
       " 'CASP8': 3.389085031356897,\n",
       " 'XIRP2': 3.1703821360088784,\n",
       " 'CUBN': 4.046813671678665,\n",
       " 'MUC17': 3.646690183663279,\n",
       " 'MUC5B': 2.0729664690136795,\n",
       " 'PCDH15': 2.6959108383640076,\n",
       " 'PCDH11X': 2.5834320206641146,\n",
       " 'AHNAK2': 2.214970513627507,\n",
       " 'FMN2': 2.615400302580672,\n",
       " 'PKHD1': 2.104351556763302,\n",
       " 'CDH10': 3.070610713909658,\n",
       " 'EP300': 3.1299077752441216,\n",
       " 'ANK2': 2.7759016074401215,\n",
       " 'RYR1': 2.9064141544880564,\n",
       " 'VCAN': 2.7374238783551403,\n",
       " 'EGFR': 3.7419164805770855}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for gene expression\n",
    "logrank(full_data,gene_expression, 2) # example: use full data and 2 years as limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5a1c0a33-2cfc-4b02-bb8f-cd8d962de3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top n genes by sort z values as features from full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbce7433-66ae-42ee-8acd-e465c1c1b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation = ['Missense_Mutation', 'Nonsense_Mutation', 'Nonstop_Mutation', 'Splice_Site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ee1209-a992-4526-a99c-59d6682dabed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Missense_Mutation': 2.2088500784074974,\n",
       " 'Nonsense_Mutation': 1.9839793008189441,\n",
       " 'Splice_Site': 5.71020812335661}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for mutation\n",
    "logrank(full_data,mutation, 2) # example: use full data and 2 years as limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f759a-15f4-4972-b042-b0f1ee0ac9c4",
   "metadata": {},
   "source": [
    "# Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ef86f5-7f1d-4f97-b556-26f460c614ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coxfitter(data, duration, event):\n",
    "    # Define the CoxPHFitter object\n",
    "    cph = CoxPHFitter()\n",
    "    # Fit the model to your data\n",
    "    cph.fit(data, duration_col= duration, event_col=event)\n",
    "    summary = cph.summary\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17689dc9-ff76-475e-97c8-522512542138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_model(df, time, lis):\n",
    "    data = df[df['DSS.time'] <= time]\n",
    "    signi = []\n",
    "    pvals = []\n",
    "    pvals_correct = []\n",
    "    for i in lis:\n",
    "        summary = coxfitter(data[[i ,'gender','ajcc_pathologic_tumor_stage', \n",
    "                                   'tumor_status', 'age', 'DSS.time', 'DSS']], 'DSS.time', 'DSS')\n",
    "        p_values = summary[\"p\"]\n",
    "        rejected, pvals_corrected = multipletests(p_values, method='fdr_bh')[:2]\n",
    "        summary['p_corrected'] = pvals_corrected\n",
    "        p = summary.loc[i, \"p\"]\n",
    "        p_correct = summary.loc[i, \"p_corrected\"]\n",
    "        pvals.append(p)\n",
    "        pvals_correct.append(p_correct)\n",
    "        signi.append(rejected[0])\n",
    "    features = [col for col in lis]  # list of features\n",
    "    # Create a DataFrame with the results\n",
    "    results = pd.DataFrame({'Features': features,'p': pvals,'p_corrected': pvals_correct, 'significant': signi})\n",
    "    return results[results['significant'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d7de60-9766-4787-8dc8-ec58dce0c5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>p</th>\n",
       "      <th>p_corrected</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CASP8</td>\n",
       "      <td>2.297870e-03</td>\n",
       "      <td>1.148935e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DNAH9</td>\n",
       "      <td>3.421607e-03</td>\n",
       "      <td>1.710804e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DNAH11</td>\n",
       "      <td>3.413931e-03</td>\n",
       "      <td>1.706965e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LRP2</td>\n",
       "      <td>1.491141e-38</td>\n",
       "      <td>7.455703e-38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RP1</td>\n",
       "      <td>2.284010e-03</td>\n",
       "      <td>1.142005e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>DNAH7</td>\n",
       "      <td>7.134398e-03</td>\n",
       "      <td>3.567199e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>MDN1</td>\n",
       "      <td>8.718074e-03</td>\n",
       "      <td>4.359037e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features             p   p_corrected  significant\n",
       "19    CASP8  2.297870e-03  1.148935e-02         True\n",
       "42    DNAH9  3.421607e-03  1.710804e-02         True\n",
       "43   DNAH11  3.413931e-03  1.706965e-02         True\n",
       "46     LRP2  1.491141e-38  7.455703e-38         True\n",
       "54      RP1  2.284010e-03  1.142005e-02         True\n",
       "59    DNAH7  7.134398e-03  3.567199e-02         True\n",
       "83     MDN1  8.718074e-03  4.359037e-02         True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gene expression level\n",
    "cox_model(full_data, 2, gene_expression )# example: use full data and 2 years as limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "046c4bea-4f38-479d-ac7b-2d6ad2c4bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>p</th>\n",
       "      <th>p_corrected</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>4.747304e-08</td>\n",
       "      <td>2.373652e-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nonsense_Mutation</td>\n",
       "      <td>3.141682e-04</td>\n",
       "      <td>1.570841e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nonstop_Mutation</td>\n",
       "      <td>8.020092e-03</td>\n",
       "      <td>4.010046e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Splice_Site</td>\n",
       "      <td>3.520589e-05</td>\n",
       "      <td>1.760294e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Features             p   p_corrected  significant\n",
       "0  Missense_Mutation  4.747304e-08  2.373652e-07         True\n",
       "1  Nonsense_Mutation  3.141682e-04  1.570841e-03         True\n",
       "2   Nonstop_Mutation  8.020092e-03  4.010046e-02         True\n",
       "3        Splice_Site  3.520589e-05  1.760294e-04         True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mutation\n",
    "cox_model(full_data, 2, mutation)# example: use full data and 2 years as limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d3fd8-2db0-4411-a33d-352dfa53e237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e0b2ec-5afc-40ad-b3b8-6176a8546f9c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "cd48e19d-21b7-4cb1-8cfe-8f802f5bec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top n mutations by z values as features columns from full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "249cc0a9-7dc6-43a4-bc81-60fdf67e97d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "#def classifcation_svm(df, features):\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import CoxPHFitter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# get features you select\n",
    "X = X_reduced\n",
    "y = full_data['DSS']\n",
    "\n",
    "# Split the dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# SVM\n",
    "\n",
    "# Define the model\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#return accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d7ee32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "X = full_data\n",
    "y = full_data['DSS']\n",
    "\n",
    "# Split the dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# SVM\n",
    "\n",
    "# Define the model\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#return accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in time_limit:\n",
    "    lis = []\n",
    "    for k in range(10000):\n",
    "        accuracy = classifcation_svm(full_data, feature_dic[i])\n",
    "        lis.append(accuracy)\n",
    "    mean_acc = sum(lis)/len(lis)\n",
    "    print('For time limit ' + str(i) + ' and gene expression features from Cox model')\n",
    "    print('SVM Accuracy ' + str(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d8a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting deepsurv\n",
      "  Downloading deepsurv-0.1.0.tar.gz (10 kB)\n",
      "Collecting theano\n",
      "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lasagne in /home/gputest/.local/lib/python3.8/site-packages (from deepsurv) (0.2.dev1)\n",
      "Requirement already satisfied: lifelines in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from deepsurv) (0.26.3)\n",
      "Requirement already satisfied: numpy in /home/gputest/.local/lib/python3.8/site-packages (from lasagne->deepsurv) (1.24.3)\n",
      "Requirement already satisfied: formulaic<0.3,>=0.2.2 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from lifelines->deepsurv) (0.2.4)\n",
      "Requirement already satisfied: autograd>=1.3 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from lifelines->deepsurv) (1.3)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from lifelines->deepsurv) (0.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /home/gputest/.local/lib/python3.8/site-packages (from lifelines->deepsurv) (3.7.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/gputest/.local/lib/python3.8/site-packages (from lifelines->deepsurv) (1.10.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /home/gputest/.local/lib/python3.8/site-packages (from lifelines->deepsurv) (1.5.3)\n",
      "Requirement already satisfied: future>=0.15.2 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from autograd>=1.3->lifelines->deepsurv) (0.18.2)\n",
      "Requirement already satisfied: astor in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from formulaic<0.3,>=0.2.2->lifelines->deepsurv) (0.8.1)\n",
      "Requirement already satisfied: interface-meta>=1.2 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from formulaic<0.3,>=0.2.2->lifelines->deepsurv) (1.2.4)\n",
      "Requirement already satisfied: wrapt in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from formulaic<0.3,>=0.2.2->lifelines->deepsurv) (1.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gputest/.local/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (4.39.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/gputest/.local/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (5.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gputest/.local/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (0.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gputest/.local/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/gputest/.local/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (20.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.0->lifelines->deepsurv) (2.4.7)\n",
      "Requirement already satisfied: six in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.0->lifelines->deepsurv) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.0->lifelines->deepsurv) (3.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gputest/.local/lib/python3.8/site-packages (from pandas>=0.23.0->lifelines->deepsurv) (2022.7.1)\n",
      "Building wheels for collected packages: deepsurv, theano\n",
      "  Building wheel for deepsurv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepsurv: filename=deepsurv-0.1.0-py3-none-any.whl size=11163 sha256=466c38c2e46dc5e789c9976ecd16fed8d462583876c293cbdd523917f6f981fa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n70xzz7s/wheels/8b/35/64/cb4fa77f7de25e6133c42cc1749ecd28b82131fcc937ab37ee\n",
      "  Building wheel for theano (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668094 sha256=ada06ea1dd9034eedd839a505e6ab6f1cb2b0b5f3fd8f608599e6f4c3ea374b4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n70xzz7s/wheels/84/cb/19/235b5b10d89b4621f685112f8762681570a9fa14dc1ce904d9\n",
      "Successfully built deepsurv theano\n",
      "Installing collected packages: theano, deepsurv\n",
      "Successfully installed deepsurv-0.1.0 theano-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb6f07e5-c0e3-493a-8add-b65825d269bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[39m=\u001b[39m full_data[\u001b[39m'\u001b[39m\u001b[39mDSS.time\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with the column representing time-to-event\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Define the Cox-Nnet model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cox_nnet_model \u001b[39m=\u001b[39m CoxPHFitter(n_iter\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, l2_reg\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m     13\u001b[0m cox_nnet_model\u001b[39m.\u001b[39mfit(X, \u001b[39m'\u001b[39m\u001b[39msurvival_time\u001b[39m\u001b[39m'\u001b[39m, event_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDSS\u001b[39m\u001b[39m'\u001b[39m, show_progress\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Replace 'event' with your actual event indicator column\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:147\u001b[0m, in \u001b[0;36mCoxPHFitter.__init__\u001b[0;34m(self, baseline_estimation_method, penalizer, strata, l1_ratio, n_baseline_knots, knots, breakpoints, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     baseline_estimation_method: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbreslow\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    145\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39msuper\u001b[39;49m(CoxPHFitter, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m l1_ratio \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m l1_ratio \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    150\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39ml1_ratio parameter must in [0, 1].\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/lifelines/fitters/__init__.py:1248\u001b[0m, in \u001b[0;36mRegressionFitter.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1248\u001b[0m     \u001b[39msuper\u001b[39;49m(RegressionFitter, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import k_fold_cross_validation\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "X = full_data[['gender', 'ajcc_pathologic_tumor_stage','DSS', 'tumor_status','TP53',\t'TTN',\t'FAT1',\t'MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "y = full_data['DSS.time']  # Replace with the column representing time-to-event\n",
    "# Define the Cox-Nnet model\n",
    "cox_nnet_model = CoxPHFitter(n_iter=1000, l2_reg=0.01)\n",
    "\n",
    "# Fit the model to the data\n",
    "cox_nnet_model.fit(X, 'survival_time', event_col='DSS', show_progress=True)  # Replace 'event' with your actual event indicator column\n",
    "\n",
    "# Calculate the concordance index (C-index) as a measure of model performance\n",
    "c_index = concordance_index(cox_nnet_model.durations, -cox_nnet_model.predict_partial_hazard(cox_nnet_model.data).values.flatten(), cox_nnet_model.event_observed)\n",
    "print(f'C-index: {c_index}')\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scores = k_fold_cross_validation(cox_nnet_model, X, 'survival_time', event_col='DSS', k=5)  # Replace 'event' with your actual event indicator column\n",
    "average_score = np.mean(scores)\n",
    "print(f'Average cross-validated C-index: {average_score}')\n",
    "'''\n",
    "E = full_data['DSS']  # Replace with the column representing event indicator\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, T_train, T_test, E_train, E_test = train_test_split(\n",
    "    X, T, E, test_size=0.2, seed=0\n",
    ")\n",
    "\n",
    "# Define the DeepSurv model architecture\n",
    "hyperparams = {'L2_reg': 1e-4, 'batch_norm': True, 'dropout': 0.2}\n",
    "architecture = [\n",
    "    {'activation': 'relu', 'num_units': 100},\n",
    "    {'activation': 'relu', 'num_units': 100},\n",
    "]\n",
    "\n",
    "# Train the DeepSurv model\n",
    "model = deep_surv.DeepSurv(architecture=architecture, hyperparams=hyperparams)\n",
    "model.fit(X_train, T_train, E_train, num_epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "c_index = model.concordance_index(X_test, T_test, E_test)\n",
    "#print(\"Concordance Index:\", c_index)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc04cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py>=2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38923efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting logger==1.4\n",
      "  Downloading logger-1.4.tar.gz (1.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: logger\n",
      "  Building wheel for logger (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for logger: filename=logger-1.4-py3-none-any.whl size=1758 sha256=d8ce13cc2ecfbb5bbe60c36468df1670cecaf6f1a02d041bf3350da082d17952\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wmjqlnmy/wheels/4c/62/b0/eb01dd1d29b9daccb651817618f8846e40384e45833f6aaf6d\n",
      "Successfully built logger\n",
      "Installing collected packages: logger\n",
      "Successfully installed logger-1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install logger==1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7977aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Optunity>=1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8b0e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_29988/3470119688.py\", line 1, in <module>\n",
      "    import theano\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/__init__.py\", line 76, in <module>\n",
      "    from theano.scan_module import scan, map, reduce, foldl, foldr, clone\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/scan_module/__init__.py\", line 40, in <module>\n",
      "    from theano.scan_module import scan_opt\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/scan_module/scan_opt.py\", line 59, in <module>\n",
      "    from theano import tensor, scalar\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/tensor/__init__.py\", line 6, in <module>\n",
      "    from theano.tensor.basic import *\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/tensor/basic.py\", line 17, in <module>\n",
      "    from theano.tensor import elemwise\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/tensor/elemwise.py\", line 13, in <module>\n",
      "    from theano import scalar\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/scalar/__init__.py\", line 2, in <module>\n",
      "    from .basic import *\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/scalar/basic.py\", line 31, in <module>\n",
      "    from theano.gradient import DisconnectedType\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/theano/gradient.py\", line 116, in <module>\n",
      "    class DisconnectedType(theano.gof.type.Type):\n",
      "AttributeError: partially initialized module 'theano' has no attribute 'gof' (most likely due to a circular import)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/gputest/.conda/envs/torch/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import theano \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dfb77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - m2w64-toolchain\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conda install m2w64-toolchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a50573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 10.5587\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3932\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3197\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6885\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2632\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9638\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7065\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5584\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4240\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3403\n",
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Fit the Cox proportional hazards model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m cox_nnet \u001b[39m=\u001b[39m CoxPHFitter()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m cox_nnet\u001b[39m.\u001b[39;49mfit(pd\u001b[39m.\u001b[39;49mDataFrame(X_train_combined), duration_col\u001b[39m=\u001b[39;49mdataset[[\u001b[39m'\u001b[39;49m\u001b[39mDSS.time\u001b[39;49m\u001b[39m'\u001b[39;49m]], event_col\u001b[39m=\u001b[39;49mdataset[[\u001b[39m'\u001b[39;49m\u001b[39mDSS\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Predict survival probabilities for the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m hidden_layer_outputs_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/utils/__init__.py:56\u001b[0m, in \u001b[0;36mCensoringType.right_censoring.<locals>.f\u001b[0;34m(model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     55\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_censoring_type(model, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mRIGHT)\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m function(model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:290\u001b[0m, in \u001b[0;36mCoxPHFitter.fit\u001b[0;34m(self, df, duration_col, event_col, show_progress, initial_point, strata, weights_col, cluster_col, robust, batch_mode, timeline, formula, entry_col, fit_options)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mFit the Cox proportional hazard model to a right-censored dataset. Alias of `fit_right_censoring`.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \n\u001b[1;32m    288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrata \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39m_to_list_or_singleton(utils\u001b[39m.\u001b[39mcoalesce(strata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrata))\n\u001b[0;32m--> 290\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_model(\n\u001b[1;32m    291\u001b[0m     df,\n\u001b[1;32m    292\u001b[0m     duration_col,\n\u001b[1;32m    293\u001b[0m     event_col\u001b[39m=\u001b[39;49mevent_col,\n\u001b[1;32m    294\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    295\u001b[0m     initial_point\u001b[39m=\u001b[39;49minitial_point,\n\u001b[1;32m    296\u001b[0m     strata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrata,\n\u001b[1;32m    297\u001b[0m     weights_col\u001b[39m=\u001b[39;49mweights_col,\n\u001b[1;32m    298\u001b[0m     cluster_col\u001b[39m=\u001b[39;49mcluster_col,\n\u001b[1;32m    299\u001b[0m     robust\u001b[39m=\u001b[39;49mrobust,\n\u001b[1;32m    300\u001b[0m     batch_mode\u001b[39m=\u001b[39;49mbatch_mode,\n\u001b[1;32m    301\u001b[0m     timeline\u001b[39m=\u001b[39;49mtimeline,\n\u001b[1;32m    302\u001b[0m     formula\u001b[39m=\u001b[39;49mformula,\n\u001b[1;32m    303\u001b[0m     entry_col\u001b[39m=\u001b[39;49mentry_col,\n\u001b[1;32m    304\u001b[0m     fit_options\u001b[39m=\u001b[39;49mfit_options,\n\u001b[1;32m    305\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:610\u001b[0m, in \u001b[0;36mCoxPHFitter._fit_model\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_model\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    609\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbaseline_estimation_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbreslow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 610\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_model_breslow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    611\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbaseline_estimation_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspline\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    612\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_model_spline(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:623\u001b[0m, in \u001b[0;36mCoxPHFitter._fit_model_breslow\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m model \u001b[39m=\u001b[39m SemiParametricPHFitter(\n\u001b[1;32m    620\u001b[0m     penalizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpenalizer, l1_ratio\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_ratio, strata\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrata, alpha\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha, label\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label\n\u001b[1;32m    621\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m utils\u001b[39m.\u001b[39mCensoringType\u001b[39m.\u001b[39mis_right_censoring(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 623\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    624\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/utils/__init__.py:56\u001b[0m, in \u001b[0;36mCensoringType.right_censoring.<locals>.f\u001b[0;34m(model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     55\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_censoring_type(model, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mRIGHT)\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m function(model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:1229\u001b[0m, in \u001b[0;36mSemiParametricPHFitter.fit\u001b[0;34m(self, df, duration_col, event_col, show_progress, initial_point, strata, weights_col, cluster_col, robust, batch_mode, timeline, formula, entry_col, fit_options)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformula \u001b[39m=\u001b[39m formula\n\u001b[1;32m   1227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_col \u001b[39m=\u001b[39m entry_col\n\u001b[0;32m-> 1229\u001b[0m X, T, E, weights, entries, original_index, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clusters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preprocess_dataframe(df)\n\u001b[1;32m   1231\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdurations \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   1232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_observed \u001b[39m=\u001b[39m E\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/lifelines/fitters/coxph_fitter.py:1305\u001b[0m, in \u001b[0;36mSemiParametricPHFitter._preprocess_dataframe\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mset_index(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrata)\n\u001b[1;32m   1304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1305\u001b[0m     sort_by \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration_col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_col] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_col \u001b[39melse\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration_col]\n\u001b[1;32m   1306\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39msort_by)\n\u001b[1;32m   1307\u001b[0m     original_index \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifelines import CoxPHFitter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset = pd.read_csv('Full Data.txt')\n",
    "#X = dataset.drop(['DSS.time', 'DSS'], axis=1)\n",
    "X = dataset[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "\n",
    "y = dataset[['DSS.time', 'DSS']]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and train the feedforward neural network\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train['DSS.time'], epochs=10, batch_size=32)\n",
    "\n",
    "# Extract the learned representations from the hidden layers\n",
    "hidden_layer_outputs = model.predict(X_train_scaled)\n",
    "\n",
    "# Combine the learned representations with the survival data\n",
    "X_train_combined = np.concatenate((X_train_scaled, hidden_layer_outputs), axis=1)\n",
    "\n",
    "# Fit the Cox proportional hazards model\n",
    "cox_nnet = CoxPHFitter()\n",
    "cox_nnet.fit(pd.DataFrame(X_train_combined), duration_col=dataset[['DSS.time']], event_col=dataset[['DSS']])\n",
    "\n",
    "# Predict survival probabilities for the test set\n",
    "hidden_layer_outputs_test = model.predict(X_test_scaled)\n",
    "X_test_combined = np.concatenate((X_test_scaled, hidden_layer_outputs_test), axis=1)\n",
    "survival_probs = cox_nnet.predict_survival_function(pd.DataFrame(X_test_combined))\n",
    "\n",
    "# Evaluate the model\n",
    "c_index = cox_nnet.score(pd.DataFrame(X_test_combined), y_test, scoring_method=\"concordance_index\")\n",
    "print(\"Concordance Index: \", c_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5018994e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('[INFO] Training CoxMLP')? (deep_surv.py, line 326)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/sahoo/Documents/Softwares/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-7-eb00348f5f86>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from deepsurv import deep_surv\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/gputest/.local/lib/python3.8/site-packages/deepsurv/__init__.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .deep_surv import DeepSurv\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/gputest/.local/lib/python3.8/site-packages/deepsurv/deep_surv.py\"\u001b[0;36m, line \u001b[0;32m326\u001b[0m\n\u001b[0;31m    print '[INFO] Training CoxMLP'\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('[INFO] Training CoxMLP')?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from deepsurv import deep_surv\n",
    "from deepsurv.datasets import load_rgbsg\n",
    "from deepsurv.utils import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06864ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have already prepared your dataset\n",
    "# X: Features (input variables)\n",
    "# y: Target variable (clinical outcome)\n",
    "X = dataset[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "\n",
    "y = dataset[['DSS.time', 'DSS']]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8cd92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'event'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msurvival:cox\u001b[39m\u001b[39m'\u001b[39m, eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcox-nloglik\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_time_train, event\u001b[39m=\u001b[39;49my_event_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'event'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming you have already prepared your dataset\n",
    "# X: Features (input variables)\n",
    "# y_time: Survival time\n",
    "# y_event: Event indicator (0: censored, 1: event occurred)\n",
    "X = dataset[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "\n",
    "y_time = dataset[['DSS.time']]\n",
    "y_event= dataset[['DSS']]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_time_train, y_time_test, y_event_train, y_event_test = train_test_split(\n",
    "    X, y_time, y_event, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective='survival:cox', eval_metric='cox-nloglik')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_time_train, event=y_event_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the concordance index (C-index)\n",
    "cindex = model.score(X_test, y_time_test, y_event_test)\n",
    "print(\"Concordance Index (C-index):\", cindex)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y_time_test, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e763b653",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (720,) (360,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(objective\u001b[39m=\u001b[39mcox_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:1923\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1923\u001b[0m     grad, hess \u001b[39m=\u001b[39m fobj(pred, dtrain)\n\u001b[1;32m   1924\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboost(dtrain, grad, hess)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/sklearn.py:107\u001b[0m, in \u001b[0;36m_objective_decorator.<locals>.inner\u001b[0;34m(preds, dmatrix)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"internal function\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m labels \u001b[39m=\u001b[39m dmatrix\u001b[39m.\u001b[39mget_label()\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m func(labels, preds)\n",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 33\u001b[0m in \u001b[0;36mcox_loss\u001b[0;34m(y_pred, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m log_risk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(np\u001b[39m.\u001b[39mcumsum(hazard_ratio))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m log_lik \u001b[39m=\u001b[39m y_pred \u001b[39m-\u001b[39m log_risk\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m neg_log_lik \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(log_lik \u001b[39m*\u001b[39;49m y_event \u001b[39m-\u001b[39m log_risk \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(y_event))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m neg_log_lik\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (720,) (360,) "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "# Assuming you have already prepared your dataset\n",
    "# X: Features (input variables)\n",
    "# y_time: Survival time\n",
    "# y_event: Event indicator (0: censored, 1: event occurred)\n",
    "X = dataset[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_time_train, y_time_test, y_event_train, y_event_test = train_test_split(\n",
    "    X, y_time, y_event, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the survival time and event indicator to the required format\n",
    "y_train = np.column_stack((y_time_train, y_event_train))\n",
    "y_test = np.column_stack((y_time_test, y_event_test))\n",
    "\n",
    "# Define the custom loss function for survival analysis\n",
    "def cox_loss(y_pred, y):\n",
    "    # Extract the survival time and event indicator\n",
    "    y_time = y[:, 0]\n",
    "    y_event = y[:, 1]\n",
    "    # Compute the negative log partial likelihood\n",
    "    hazard_ratio = np.exp(y_pred)\n",
    "    log_risk = np.log(np.cumsum(hazard_ratio))\n",
    "    log_lik = y_pred - log_risk\n",
    "    neg_log_lik = -np.sum(log_lik * y_event - log_risk * np.sum(y_event))\n",
    "    return neg_log_lik\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective=cox_loss)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the concordance index (C-index)\n",
    "cindex = concordance_index(y_time_test, -y_pred, y_event_test)\n",
    "print(\"Concordance Index (C-index):\", cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ee1390",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float32 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(objective\u001b[39m=\u001b[39mcox_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:1923\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1923\u001b[0m     grad, hess \u001b[39m=\u001b[39m fobj(pred, dtrain)\n\u001b[1;32m   1924\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboost(dtrain, grad, hess)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float32 object"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "y = full_data[['DSS']]\n",
    "def cox_loss(y_pred, y):\n",
    "    # Extract the survival time and event indicator\n",
    "    # Compute the negative log partial likelihood\n",
    "    hazard_ratio = np.exp(y_pred)\n",
    "    log_risk = np.log(np.cumsum(hazard_ratio))\n",
    "    log_lik = y_pred - log_risk\n",
    "    neg_log_lik = -np.sum(log_lik * y - log_risk * np.sum(y))\n",
    "    return neg_log_lik\n",
    "\n",
    "X = full_data[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation',\t'Nonsense_Mutation',\t'Nonstop_Mutation',\t'Splice_Site',\t'age']]  # Replace with the actual feature columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective=cox_loss)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the concordance index (C-index)\n",
    "cindex = concordance_index(ytest, -y_pred, y_test)\n",
    "print(\"Concordance Index (C-index):\", cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d115cc6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float32 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(objective\u001b[39m=\u001b[39mcox_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgene-gpu.ucsd.edu/data/space1/BooleanLab/Atishna/ece204/project5train.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf-3/lib/python3.8/site-packages/xgboost/core.py:1923\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1923\u001b[0m     grad, hess \u001b[39m=\u001b[39m fobj(pred, dtrain)\n\u001b[1;32m   1924\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboost(dtrain, grad, hess)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float32 object"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "y = full_data[['DSS']].values  # Convert to NumPy array\n",
    "X = full_data[['gender', 'ajcc_pathologic_tumor_stage', 'tumor_status','TP53','TTN','FAT1','MUC16','CLCA4','EGFR','Missense_Mutation','Nonsense_Mutation','Nonstop_Mutation','Splice_Site','age']].values  # Convert to NumPy array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the custom loss function for survival analysis\n",
    "def cox_loss(y_pred, y):\n",
    "    hazard_ratio = np.exp(y_pred)\n",
    "    log_risk = np.log(np.cumsum(hazard_ratio))\n",
    "    log_lik = y_pred - log_risk\n",
    "    neg_log_lik = -np.sum(log_lik * y - log_risk * np.sum(y))\n",
    "    return neg_log_lik\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor(objective=cox_loss)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the concordance index (C-index)\n",
    "cindex = concordance_index(y_test, -y_pred, np.squeeze(y_test))\n",
    "print(\"Concordance Index (C-index):\", cindex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "946e2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (360, 14)\n",
      "y_train shape: (360, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
